{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPvtzD2M5OO86fYBjhIvh7v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shengpu-tang/CS334-S25/blob/main/HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 3 - Predicting Survival of ICU Patients"
      ],
      "metadata": {
        "id": "AB1hMQjCH0VL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5csNrwwz1hC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run this code block to download and unzip data\n",
        "#@markdown - If you already have the data in your workspace, you can skip this step.\n",
        "#@markdown - If you want to reset your workspace, use menu \"Runtime - Disconnect and delete runtime\".\n",
        "#@markdown - To save your work in this notebok, use menu \"File - Save a copy in Drive...\"\n",
        "\n",
        "!rm -rf config.yaml data.zip data\n",
        "!wget -q \"https://raw.githubusercontent.com/shengpu-tang/CS334-F24/main/HW3/config.yaml\"\n",
        "!wget -q \"https://raw.githubusercontent.com/shengpu-tang/CS334-F24/main/HW3/data.zip\"\n",
        "!unzip -qq data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title HW3 - helper.py\n",
        "# @markdown This block contains the content of the helper file so you don't need to download it separately.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import yaml\n",
        "config = yaml.load(open('config.yaml'), Loader=yaml.FullLoader)\n",
        "\n",
        "def get_train_test_split():\n",
        "    \"\"\"\n",
        "    This function performs the following steps:\n",
        "    - Reads in the data from data/labels.csv and data/files/*.csv (keep only the first 2,500 examples)\n",
        "    - Generates a feature vector for each example\n",
        "    - Aggregates feature vectors into a feature matrix (features are sorted alphabetically by name)\n",
        "    - Performs imputation and normalization with respect to the population\n",
        "\n",
        "    After all these steps, it splits the data into 80% train and 20% test.\n",
        "\n",
        "    The binary labels take two values:\n",
        "        -1: survivor\n",
        "        +1: died in hospital\n",
        "\n",
        "    Returns the features and labesl for train and test sets, followed by the names of features.\n",
        "    \"\"\"\n",
        "    df_labels = pd.read_csv('data/labels.csv')\n",
        "    df_labels = df_labels[:2500]\n",
        "    IDs = df_labels['RecordID'][:2500]\n",
        "    raw_data = {}\n",
        "    for i in tqdm(IDs, desc='Loading files from disk'):\n",
        "        raw_data[i] = pd.read_csv('data/files/{}.csv'.format(i))\n",
        "\n",
        "    features = Parallel(n_jobs=16)(delayed(generate_feature_vector)(df) for _, df in tqdm(raw_data.items(), desc='Generating feature vectors'))\n",
        "    df_features = pd.DataFrame(features).sort_index(axis=1)\n",
        "    feature_names = df_features.columns.tolist()\n",
        "    X, y = df_features.values, df_labels['In-hospital_death'].values\n",
        "    X = impute_missing_values(X)\n",
        "    X = normalize_feature_matrix(X)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, random_state=3)\n",
        "    return X_train, y_train, X_test, y_test, feature_names\n",
        "\n",
        "\n",
        "def get_classifier(penalty='l2', C=1.0, class_weight=None):\n",
        "    \"\"\"\n",
        "    Returns a logistic regression classifier based on the given\n",
        "    penalty function, regularization parameter C, and class weights.\n",
        "    \"\"\"\n",
        "    if penalty == 'l2':\n",
        "        return LogisticRegression(penalty=penalty, C=C, class_weight=class_weight, solver='lbfgs', max_iter=1000)\n",
        "    elif penalty == 'l1':\n",
        "        return LogisticRegression(penalty=penalty, C=C, class_weight=class_weight, solver='saga', max_iter=5000)\n",
        "    else:\n",
        "        raise ValueError('Error: unsupported configuration')\n",
        "\n",
        "\n",
        "def make_challenge_submission(y_label, y_score):\n",
        "    \"\"\"\n",
        "    Takes in `y_label` and `y_score`, which are two list-like objects that contain\n",
        "    both the binary predictions and raw scores from your classifier.\n",
        "    Outputs the prediction to challenge.csv.\n",
        "\n",
        "    Please make sure that you do not change the order of the test examples in the heldout set\n",
        "    since we will use this file to evaluate your classifier.\n",
        "    \"\"\"\n",
        "    print('Saving challenge output...')\n",
        "    pd.DataFrame({'label': y_label.astype(int), 'risk_score': y_score}).to_csv('challenge.csv', index=False)\n",
        "    print('challenge.csv saved')\n",
        "    return\n",
        "\n",
        "\n",
        "def test_challenge_output():\n",
        "    import csv\n",
        "    with open('challenge.csv', newline='') as csvfile:\n",
        "        filereader = csv.reader(csvfile)\n",
        "        i = 0\n",
        "        for row in filereader:\n",
        "            if i == 0:\n",
        "                if row[0] != 'label':\n",
        "                    print('INVALID COLUMN NAME: column name is not label.')\n",
        "            else:\n",
        "                rating = int(row[0])\n",
        "                if rating != -1 and rating != 0 and rating != 1:\n",
        "                    print('INVALID VALUE: values need to be -1, 0, or 1.')\n",
        "            i += 1\n",
        "        if i != 2001:\n",
        "            print('INVALID NUMBER OF ROWS: number of rows is not 2001.')\n",
        "        print('SUCCESS: csv file is valid.')\n",
        "    return"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Zyc936PT4V8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import packages"
      ],
      "metadata": {
        "id": "KLNLqRn7Eci5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import metrics, exceptions\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=exceptions.UndefinedMetricWarning)"
      ],
      "metadata": {
        "id": "cBfmbZW707Wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Feature Extraction"
      ],
      "metadata": {
        "id": "pmr0sbTTEfCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_feature_vector(df):\n",
        "    \"\"\"\n",
        "    Reads a dataframe containing all measurements for a single patient\n",
        "    within the first 48 hours of the ICU admission, and convert it into\n",
        "    a feature vector.\n",
        "\n",
        "    Input:\n",
        "        df: pd.Dataframe, with columns [Time, Variable, Value]\n",
        "\n",
        "    Returns:\n",
        "        a python dictionary of format {feature_name: feature_value}\n",
        "        for example, {'Age': 32, 'Gender': 0, 'mean_HR': 84, ...}\n",
        "    \"\"\"\n",
        "    static_variables = config['static']\n",
        "    timeseries_variables = config['timeseries']\n",
        "    feature_dict = {}\n",
        "\n",
        "    # TODO: Implement this function\n",
        "    ???\n",
        "\n",
        "    return feature_dict\n",
        "\n",
        "\n",
        "def impute_missing_values(X):\n",
        "    \"\"\"\n",
        "    For each feature column, impute missing values  (np.nan) with the\n",
        "    population mean for that feature.\n",
        "\n",
        "    Input:\n",
        "        X: np.array, shape (N, d). X could contain missing values\n",
        "    Returns:\n",
        "        X: np.array, shape (N, d). X does not contain any missing values\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    ???\n",
        "    return X\n",
        "\n",
        "\n",
        "def normalize_feature_matrix(X):\n",
        "    \"\"\"\n",
        "    For each feature column, normalize all values to range [0, 1].\n",
        "\n",
        "    Input:\n",
        "        X: np.array, shape (N, d).\n",
        "    Returns:\n",
        "        X: np.array, shape (N, d). Values are normalized per column.\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    ???\n",
        "    return X\n"
      ],
      "metadata": {
        "id": "fHHxXOwy07UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def q1(X, feature_names):\n",
        "    \"\"\"\n",
        "    Given a feature matrix X, prints d, the number of features in the feature vector,\n",
        "    and prints the average feature vector along with its corresponing feature name.\n",
        "    \"\"\"\n",
        "    ##################################################################\n",
        "    print(\"--------------------------------------------\")\n",
        "    print(\"Question 1(d): reporting dataset statistics:\")\n",
        "    print(\"\\t\", \"d:\", X.shape[1])\n",
        "    print(\"\\t\", \"Average feature vector:\")\n",
        "    print(pd.DataFrame({\"Feature Name\": feature_names, \"Mean value\": X.mean(axis=0)}))"
      ],
      "metadata": {
        "id": "JEPFM9prErD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data\n",
        "# NOTE: READING IN THE DATA WILL NOT WORK UNTIL YOU HAVE FINISHED\n",
        "#       IMPLEMENTING generate_feature_vector, fill_missing_values AND normalize_feature_matrix\n",
        "X_train, y_train, X_test, y_test, feature_names = get_train_test_split()"
      ],
      "metadata": {
        "id": "mxRiRiGYVWoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q1(X_train, feature_names)"
      ],
      "metadata": {
        "id": "w5jBY9M27Wte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Hyperparameter and Model Selection"
      ],
      "metadata": {
        "id": "A-3bQxcwEjZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def performance(clf, X, y_true, metric='accuracy'):\n",
        "    \"\"\"\n",
        "    Calculates the performance metric as evaluated on the true labels\n",
        "    y_true versus the predicted scores from clf and X.\n",
        "    Input:\n",
        "        clf: an instance of sklearn estimator\n",
        "        X : (N,d) np.array containing features\n",
        "        y_true: (N,) np.array containing true labels\n",
        "        metric: string specifying the performance metric (default='accuracy'\n",
        "                 other options: 'precision', 'sensitivity', 'specificity',\n",
        "                'f1-score', 'auroc', and 'auprc')\n",
        "    Returns:\n",
        "        the performance measure as a float\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    ???\n",
        "\n",
        "\n",
        "def cv_performance(clf, X, y, k=5, metric='accuracy'):\n",
        "    \"\"\"\n",
        "    Splits the data X and the labels y into k folds.\n",
        "    Then, for each fold i in 1...k,\n",
        "        Train a classifier on all the data except the i-th fold, and test on the i-th fold.\n",
        "        Calculate the performance of the classifier and save the result.\n",
        "    In the end, return the average performance across the k folds.\n",
        "    Input:\n",
        "        clf: an instance of sklearn estimator\n",
        "        X: (N,d) array of feature vectors, where n is the number of examples\n",
        "           and d is the number of features\n",
        "        y: (N,) array of binary labels {1,-1}\n",
        "        k: an int specifying the number of folds (default=5)\n",
        "        metric: string specifying the performance metric (default='accuracy'\n",
        "             other options: 'precision', 'sensitivity', 'specificity',\n",
        "                'f1-score', 'auroc', and 'auprc')\n",
        "    Returns:\n",
        "        average cross-validation performance across the k folds as a float\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    skf = StratifiedKFold(n_splits=k)\n",
        "    scores = []\n",
        "    # For each split in the k folds...\n",
        "    for train, val in skf.split(X,y):\n",
        "        # Split the data into training and validation sets...\n",
        "        X_train, y_train, X_val, y_val = ???\n",
        "        # Fit the data to the training data...\n",
        "        ???\n",
        "        # And test on the ith fold.\n",
        "        score = ???\n",
        "        scores.append(score)\n",
        "    # Return the average performance across all fold splits.\n",
        "    return np.array(scores).mean()\n",
        "\n",
        "\n",
        "def select_C(X, y, C_range=[], penalty='l2', k=5, metric='accuracy'):\n",
        "    \"\"\"\n",
        "    Sweeps different C hyperparameters of a logistic regression classifier,\n",
        "    calculates the k-fold CV performance for each setting on dataset (X, y),\n",
        "    and return the best C.\n",
        "    Input:\n",
        "        X: (N,d) array of feature vectors, where N is the number of examples\n",
        "            and d is the number of features\n",
        "        y: (N,) array of binary labels {1,-1}\n",
        "        k: int specifying the number of folds for cross-validation (default=5)\n",
        "        metric: string specifying the performance metric (default='accuracy',\n",
        "             other options: 'precision', 'sensitivity', 'specificity',\n",
        "                'f1-score', 'auroc', and 'auprc')\n",
        "        penalty: whether to use 'l1' or 'l2' regularization (default='l2')\n",
        "        C_range: a list of hyperparameter C values to be searched over\n",
        "    Returns:\n",
        "        the C value for a logistic regression classifier that maximizes\n",
        "        the average 5-fold CV performance.\n",
        "    \"\"\"\n",
        "    print(\"{}-regularized Logistic Regression \"\n",
        "          \"Hyperparameter Selection based on {}:\".format(penalty.upper(), metric))\n",
        "    scores = []\n",
        "    # Iterate over all of the given C range...\n",
        "    for C in C_range:\n",
        "        # Calculate the average performance on k-fold cross-validation\n",
        "        clf = get_classifier(penalty=penalty, C=C)\n",
        "        score = cv_performance(clf, X, y, k, metric)\n",
        "        print(\"C: {:.6f} \\t score: {:.4f}\".format(C, score))\n",
        "        scores.append((C, score))\n",
        "    # Return the C value with the maximum score\n",
        "    maxval = max(scores, key=lambda x: x[1])\n",
        "    return maxval[0]\n",
        "\n",
        "\n",
        "def plot_coefficients(X, y, penalty, C_range):\n",
        "    \"\"\"\n",
        "    Takes as input the training data X and labels y and plots the L0-norm\n",
        "    (number of nonzero elements) of the coefficients learned by a classifier\n",
        "    as a function of the C-values of the classifier.\n",
        "    \"\"\"\n",
        "    print(\"Plotting the number of nonzero entries of the parameter vector as a function of C\")\n",
        "    norm0 = []\n",
        "\n",
        "    # TODO: Implement this function\n",
        "    ???\n",
        "\n",
        "    # This code will plot your L0-norm as a function of C\n",
        "    plt.plot(C_range, norm0)\n",
        "    plt.axhline(y=X.shape[1], color='gray', linestyle=':')\n",
        "    plt.xscale('log')\n",
        "    plt.legend(['L0-norm'])\n",
        "    plt.xlabel(\"Value of C\")\n",
        "    plt.ylabel(\"L0-norm of theta\")\n",
        "    plt.ylim(-2,50)\n",
        "    plt.title('L0-norm of Î¸ vs C, {}-penalized logistic regression'.format(penalty.upper()))\n",
        "    plt.savefig('l0-norm_vs_C__'+penalty+'-penalty.png', dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "    print('Plot saved')"
      ],
      "metadata": {
        "id": "RMK6LKa90KbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def q2(X_train, y_train, X_test, y_test, metric_list, feature_names):\n",
        "    \"\"\"\n",
        "    This function should contain all the code you implement to complete part 2\n",
        "    \"\"\"\n",
        "    print(\"================= Part 2 ===================\")\n",
        "\n",
        "    C_range = np.logspace(-3, 3, 7)\n",
        "\n",
        "    ##################################################################\n",
        "    print(\"--------------------------------------------\")\n",
        "    print(\"Question 2.1(c): Logistic Regression with L2-penalty, grid search, all metrics\")\n",
        "    for metric in metric_list:\n",
        "        best_C = select_C(X_train, y_train, C_range, 'l2', 5, metric)\n",
        "        print(\"Best C: %.6f\" % best_C)\n",
        "\n",
        "    ##################################################################\n",
        "    print(\"--------------------------------------------\")\n",
        "    print(\"Question 2.1(d): Test Performance of L2-reg logistic regression with best C\")\n",
        "    best_C  = ???\n",
        "    ??? # Fit the classifier with the best C\n",
        "    for metric in metric_list:\n",
        "        test_perf = performance(clf, X_test, y_test, metric)\n",
        "        print(\"C = \" + str(best_C) + \" Test Performance on metric \" + metric + \": %.4f\" % test_perf)\n",
        "\n",
        "    ##################################################################\n",
        "    print(\"--------------------------------------------\")\n",
        "    print(\"Question 2.1(e): Plot L0-norm of theta coefficients vs. C, l2 penalty\")\n",
        "    plot_coefficients(X_train, y_train, 'l2', C_range)\n",
        "\n",
        "    ##################################################################\n",
        "    print(\"--------------------------------------------\")\n",
        "    print(\"Question 2.1(f): Displaying the most positive and negative coefficients and features\")\n",
        "    best_C = ???\n",
        "    print('Positive coefficients...')\n",
        "    print('Negative coefficients...')\n",
        "\n",
        "    ##################################################################\n",
        "    print(\"--------------------------------------------\")\n",
        "    print(\"Question 2.2(a): Logistic Regression with L1-penalty, grid search, AUROC\")\n",
        "    best_C = ???\n",
        "    test_performance = ???\n",
        "\n",
        "    ##################################################################\n",
        "    print(\"--------------------------------------------\")\n",
        "    print(\"Question 2.2(b): Plot the weights of C vs. L0-norm of theta, l1 penalty\")\n",
        "    plot_coefficients(X_train, y_train, 'l1', C_range)"
      ],
      "metadata": {
        "id": "9Jy9q3Om1KJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_list = [\"accuracy\", \"precision\", \"sensitivity\", \"specificity\", \"f1_score\", \"auroc\", \"auprc\"]"
      ],
      "metadata": {
        "id": "_OPsFJg79MwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q2(X_train, y_train, X_test, y_test, metric_list, feature_names)"
      ],
      "metadata": {
        "id": "jGW0zM9n9JMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Challenge"
      ],
      "metadata": {
        "id": "qCH9y3fjGjxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_feature_vector_challenge(df):\n",
        "    return generate_feature_vector(df)\n",
        "\n",
        "def impute_missing_values_challenge(X):\n",
        "    return impute_missing_values(X)\n",
        "\n",
        "def normalize_feature_matrix_challenge(X):\n",
        "    return normalize_feature_matrix(X)"
      ],
      "metadata": {
        "id": "IkDAUZeV8Iyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_challenge_data():\n",
        "    \"\"\"\n",
        "    This function is similar to helper.get_train_test_split, except that:\n",
        "    - It reads in all 10,000 training examples\n",
        "    - It does not return labels for the 2,000 examples in the heldout test set\n",
        "    You should replace your preprocessing functions (generate_feature_vector,\n",
        "    impute_missing_values, normalize_feature_matrix) with updated versions for the challenge\n",
        "    \"\"\"\n",
        "    df_labels = pd.read_csv('data/labels.csv')\n",
        "    df_labels = df_labels\n",
        "    IDs = df_labels['RecordID']\n",
        "    raw_data = {}\n",
        "    for i in tqdm(IDs, desc='Loading files from disk'):\n",
        "        raw_data[i] = pd.read_csv('data/files/{}.csv'.format(i))\n",
        "\n",
        "    features = Parallel(n_jobs=16)(delayed(generate_feature_vector_challenge)(df) for _, df in tqdm(raw_data.items(), desc='Generating feature vectors'))\n",
        "    df_features = pd.DataFrame(features)\n",
        "    feature_names = df_features.columns.tolist()\n",
        "    X, y = df_features.values, df_labels['30-day_mortality'].values\n",
        "    X = impute_missing_values_challenge(X)\n",
        "    X = normalize_feature_matrix_challenge(X)\n",
        "    return X[:10000], y[:10000], X[10000:], feature_names"
      ],
      "metadata": {
        "id": "QMrodAElHS0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_challenge(X_challenge, y_challenge, X_heldout):\n",
        "    # TODO:\n",
        "    # Read challenge data\n",
        "    # Train a linear classifier and apply to heldout dataset features\n",
        "    # Use generate_challenge_labels to print the predicted labels\n",
        "    print(\"================= Part 3 ===================\")\n",
        "    print(\"Part 3: Challenge\")\n",
        "    clf = LogisticRegression() ### TODO: define your classifier with appropriate hyperparameters\n",
        "    clf.fit(X_challenge, y_challenge)\n",
        "    y_score = clf.decision_function(X_heldout)\n",
        "    y_label = clf.predict(X_heldout)\n",
        "    make_challenge_submission(y_label, y_score)"
      ],
      "metadata": {
        "id": "BwSOZKsPFe37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read challenge data\n",
        "X_challenge, y_challenge, X_heldout, feature_names = get_challenge_data()"
      ],
      "metadata": {
        "id": "Vv5quz_zU4Yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Question 3: Apply a classifier to heldout features, and then use\n",
        "#       generate_challenge_labels to print the predicted labels\n",
        "run_challenge(X_challenge, y_challenge, X_heldout)\n",
        "test_challenge_output()"
      ],
      "metadata": {
        "id": "I3y5eBMmSiwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bEcZY7LDFO91"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}