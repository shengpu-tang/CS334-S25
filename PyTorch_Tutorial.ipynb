{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shengpu-tang/CS334-S25/blob/main/PyTorch_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Tutorial\n",
        "\n",
        "References:\n",
        "- https://playground.tensorflow.org/\n",
        "- Quickstart: https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
        "- Linear / fully-connected layers: https://pytorch.org/docs/main/nn.html#linear-layers\n",
        "  - [`torch.nn.Linear`](https://pytorch.org/docs/main/generated/torch.nn.Linear.html)\n",
        "- Activation functions: found in https://pytorch.org/docs/main/nn.functional.html\n",
        "- Loss functions: https://pytorch.org/docs/main/nn.html#loss-functions\n",
        "  - [`torch.nn.BCELoss`](https://pytorch.org/docs/main/generated/torch.nn.BCELoss.html)\n",
        "  - [`torch.nn.CrossEntropyLoss`](https://pytorch.org/docs/main/generated/torch.nn.CrossEntropyLoss.html)\n"
      ],
      "metadata": {
        "id": "F5AdAYdLwUsS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dq7ANHgTzQ_o"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%config InlineBackend.figure_formats = ['svg']"
      ],
      "metadata": {
        "id": "2muZmkUe0D8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "5XwqzCQRlLxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this code block to define plotting helper functions\n",
        "#@markdown This defines `plot_boundary(X, pred)` which can plot the decision boundary of a neural network\n",
        "from matplotlib import cm, ticker\n",
        "\n",
        "MARKERS = ['o', 'v', '+']\n",
        "COLORS = ['red', 'green', 'blue']\n",
        "rgb_gradient_cmap = matplotlib.colors.ListedColormap(COLORS)\n",
        "red_cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"RedGradient\", [(1, 0, 0, 0), (1, 0, 0, 1)])  # Transparent to red\n",
        "green_cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"GreenGradient\", [(0, 1, 0, 0), (0, 1, 0, 1)])  # Transparent to green\n",
        "blue_cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"BlueGradient\", [(0, 0, 1, 0), (0, 0, 1, 1)])  # Transparent to blue\n",
        "\n",
        "def plot_points(X, y):\n",
        "    for i, label in enumerate(set(y)):\n",
        "        points = X[y == label]\n",
        "        marker = MARKERS[i % len(MARKERS)]\n",
        "        color = COLORS[i % len(COLORS)]\n",
        "        plt.scatter(points[:,0], points[:,1], marker=marker, color=color)\n",
        "\n",
        "    plt.xlabel(\"Feature 1\")\n",
        "    plt.ylabel(\"Feature 2\")\n",
        "\n",
        "def predict(model, x):\n",
        "    with torch.no_grad():\n",
        "        o = net(torch.from_numpy(x).float())\n",
        "    return o.numpy()\n",
        "\n",
        "def plot_boundary(X, pred, num_classes=2):\n",
        "    # Define grid limits based on current plot or data\n",
        "    try:\n",
        "        x_min, x_max = plt.gca().get_xlim()\n",
        "        y_min, y_max = plt.gca().get_ylim()\n",
        "    except:\n",
        "        x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
        "        y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
        "\n",
        "    # Generate mesh grid\n",
        "    xs, ys = np.meshgrid(\n",
        "        np.linspace(x_min, x_max, 200),\n",
        "        np.linspace(y_min, y_max, 200)\n",
        "    )\n",
        "    xys = np.column_stack([xs.ravel(), ys.ravel()])\n",
        "\n",
        "    # Make predictions over the grid points\n",
        "    try:\n",
        "        zs = pred(xys)\n",
        "        if num_classes == 2:\n",
        "            # Binary case: plot boundary based on probability threshold 0.5\n",
        "            zs = zs.reshape(xs.shape)\n",
        "            plt.contour(xs, ys, (zs >= 0.5).astype(int), colors='grey')\n",
        "            plt.imshow(zs, cmap=\"PiYG\", vmin=-0.2, vmax=1.2, alpha=0.4, origin='lower', extent=[x_min, x_max, y_min, y_max])\n",
        "        else:\n",
        "            # Multi-class case: color - gradient for each\n",
        "            zzs = np.exp(zs) / np.sum(np.exp(zs), axis=1, keepdims=True)\n",
        "            Z1 = zzs[:, 0].reshape(xs.shape)\n",
        "            Z2 = zzs[:, 1].reshape(xs.shape)\n",
        "            Z3 = zzs[:, 2].reshape(xs.shape)\n",
        "            plt.imshow(Z1, cmap=red_cmap, origin='lower', alpha=0.6, extent=[x_min, x_max, y_min, y_max])\n",
        "            plt.imshow(Z2, cmap=green_cmap, origin='lower', alpha=0.6, extent=[x_min, x_max, y_min, y_max])\n",
        "            plt.imshow(Z3, cmap=blue_cmap, origin='lower', alpha=0.6, extent=[x_min, x_max, y_min, y_max])\n",
        "\n",
        "            # Multi-class case: boundary - take the argmax over classes\n",
        "            zs = np.argmax(zs, axis=1).reshape(xs.shape)\n",
        "            plt.contour(xs, ys, zs, levels=np.arange(num_classes), colors='grey')\n",
        "\n",
        "            # plt.imshow(zs, cmap=rgb_gradient_cmap, alpha=0.4, origin='lower', extent=[x_min, x_max, y_min, y_max])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in plotting decision boundary: {e}\")\n",
        "        zs = pred(xys)\n",
        "        plt.contour(xs, ys, zs.reshape(xs.shape), colors='grey')\n",
        "\n",
        "    plt.xlim(x_min, x_max)\n",
        "    plt.ylim(y_min, y_max)\n",
        "    plt.title(\"Decision Boundary\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0PdiWZd_0aS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "k-kPbvmczQ_r"
      },
      "outputs": [],
      "source": [
        "#@title Run this code block to define datasets\n",
        "#@markdown - `D1(N)`: binary classificaiton, linear decision boundary\n",
        "#@markdown - `D2(N)`: binary classificaiton, non-linear decision boundary\n",
        "#@markdown - `D3(N)`: multiclass classification\n",
        "\n",
        "class D1(Dataset):\n",
        "    def __init__(self, N=50):\n",
        "        super().__init__()\n",
        "        rng = np.random.default_rng(0)\n",
        "        self.X = np.r_[2.0 * rng.standard_normal((N//2, 2)) - [2, 2], 2.0 * rng.standard_normal((N//2, 2)) + [2, 2]]\n",
        "        self.y = np.array([0] * (N//2) + [1] * (N//2))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(self.X[idx]).float(), torch.tensor([self.y[idx]]).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "\n",
        "class D2(Dataset):\n",
        "    def __init__(self, N=50):\n",
        "        super().__init__()\n",
        "        rng = np.random.default_rng(0)\n",
        "        X = 3.0 * rng.standard_normal((N, 2))\n",
        "        y = np.array([0] * N)\n",
        "        y[np.diag(X@X.T)>10] = 1\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(self.X[idx]).float(), torch.tensor([self.y[idx]]).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "\n",
        "class D3(Dataset):\n",
        "    def __init__(self, N=50):\n",
        "        super().__init__()\n",
        "        rng = np.random.default_rng(0)\n",
        "        X = 3.0 * rng.standard_normal((N, 2))\n",
        "        y = np.array([0] * N)\n",
        "        y[np.diag(X@X.T) < 6] = 1\n",
        "        y[(np.diag(X@X.T) >= 6) & (X@np.array([1,2]) >= 0)] = 2\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(self.X[idx]).float(), torch.tensor(self.y[idx]).long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backprop demo\n",
        "\n",
        "Linear regression with mean squared error loss\n",
        "\n",
        "$$ L = \\frac{1}{2} (w x + b - y)^2 $$\n",
        "$$\\frac{\\partial L}{\\partial w} = (w x + b - y) x$$\n",
        "$$\\frac{\\partial L}{\\partial b} = (w  x +b - y)$$"
      ],
      "metadata": {
        "id": "0p9GyIl-8oC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(nn.Linear(2, 1))\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "dNl5O3PW8qnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and clear gradients\n",
        "nn.init.zeros_(net[0].weight)\n",
        "nn.init.zeros_(net[0].bias)\n",
        "try:\n",
        "    net[0].weight.grad.zero_()\n",
        "    net[0].bias.grad.zero_()\n",
        "except:\n",
        "    pass\n",
        "\n",
        "print('Initial parameters')\n",
        "print('w =', net[0].weight.data)\n",
        "print('b =', net[0].bias.data)\n",
        "\n",
        "# Forward pass\n",
        "x = torch.tensor([1,2]).float()\n",
        "y_true = torch.tensor([1]).float()\n",
        "y_hat = ...\n",
        "loss = ...\n",
        "print()\n",
        "print('Forward pass')\n",
        "print('y_hat =', y_hat.data)\n",
        "print('loss. =', loss.data)\n",
        "\n",
        "# Backward pass\n",
        "...\n",
        "print()\n",
        "print('Gradients')\n",
        "print('dw =', net[0].weight.grad)\n",
        "print('db =', net[0].bias.grad)\n",
        "\n",
        "# Update\n",
        "...\n",
        "print()\n",
        "print('Updated parameters')\n",
        "print('w =', net[0].weight.data)\n",
        "print('b =', net[0].bias.data)"
      ],
      "metadata": {
        "id": "nUQ6BoGH8p4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Net Training - Example"
      ],
      "metadata": {
        "id": "EuWxCUx6lvsN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5CTDRzxzQ_t"
      },
      "outputs": [],
      "source": [
        "d1 = D1(100)\n",
        "plt.figure(figsize=(5,5))\n",
        "plot_points(d1.X, d1.y)\n",
        "plt.axis('equal')\n",
        "plt.xlim(-8, 8)\n",
        "plt.ylim(-8, 8)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsuH20fYzQ_t"
      },
      "source": [
        "### Define the neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qM4HRbKEzQ_t"
      },
      "outputs": [],
      "source": [
        "class Net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # TODO: put neural net structure here\n",
        "        ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: define the forward pass here\n",
        "        ...\n",
        "        return ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtEJ1ywfzQ_u"
      },
      "outputs": [],
      "source": [
        "torch.random.manual_seed(2)\n",
        "net = Net1()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4uL1kv_zQ_u"
      },
      "outputs": [],
      "source": [
        "# How many float-valued parameters are there?\n",
        "print('Number of learnable float-valued parameters', count_parameters(net))\n",
        "print('Neural net architecture:')\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaQLWgS4zQ_u"
      },
      "source": [
        "### Before training..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What are the parameter values before training?\n",
        "for name, param in net.named_parameters():\n",
        "    print(name, '\\t', param.data)"
      ],
      "metadata": {
        "id": "n17UXkvjmxWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vt6zNpQgzQ_u"
      },
      "outputs": [],
      "source": [
        "# Where is the decision boundary before training?\n",
        "plt.figure(figsize=(5,5))\n",
        "plot_points(d1.X, d1.y)\n",
        "plt.axis('equal')\n",
        "plt.xlim(-8, 8)\n",
        "plt.ylim(-8, 8)\n",
        "plot_boundary(d1.X, lambda x: predict(net, x))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train!"
      ],
      "metadata": {
        "id": "FkM0huR-wJWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training set, loss function, and optimization algorithm\n",
        "dataloader = ...\n",
        "criterion = ...\n",
        "optimizer = ..."
      ],
      "metadata": {
        "id": "yKrf-LwSmeN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-R1x4rKSzQ_v"
      },
      "outputs": [],
      "source": [
        "# Trainer loop\n",
        "for epoch in tqdm(range(1000)):\n",
        "    for X, y in dataloader:\n",
        "        ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC9wJEBtzQ_v"
      },
      "source": [
        "### After training..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What are the parameter values before training?\n",
        "for name, param in net.named_parameters():\n",
        "    print(name, '\\t', param.data)"
      ],
      "metadata": {
        "id": "yL5Sd8f8m2w0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPQzloBhzQ_v"
      },
      "outputs": [],
      "source": [
        "# Where is the decision boundary after training?\n",
        "plt.figure(figsize=(5,5))\n",
        "plot_points(d1.X, d1.y)\n",
        "plt.axis('equal')\n",
        "plt.xlim(-8, 8)\n",
        "plt.ylim(-8, 8)\n",
        "plot_boundary(d1.X, lambda x: predict(net, x))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise Q2: non-linear decision boundary"
      ],
      "metadata": {
        "id": "kIl4CQkp38Yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data\n",
        "d2 = D2(100)\n",
        "plt.figure(figsize=(5,5))\n",
        "plot_points(d2.X, d2.y)\n",
        "plt.axis('equal')\n",
        "plt.xlim(-8, 8)\n",
        "plt.ylim(-8, 8)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "obT6or4Vx9vJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "class Net2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # TODO: put neural net structure here\n",
        "        ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: define the forward pass here\n",
        "        ...\n",
        "\n",
        "net = Net2()\n",
        "\n",
        "print('Number of learnable float-valued parameters', count_parameters(net))\n",
        "print('Neural net architecture:')\n",
        "print(net)"
      ],
      "metadata": {
        "id": "L9RmO6d2x_ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What are the parameter values before training?\n",
        "for name, param in net.named_parameters():\n",
        "    print(name, '\\t', param.data)\n",
        "\n",
        "# Where is the decision boundary before training?\n",
        "plt.figure(figsize=(5,5))\n",
        "plot_points(d2.X, d2.y)\n",
        "plt.axis('equal')\n",
        "plt.xlim(-8, 8)\n",
        "plt.ylim(-8, 8)\n",
        "plot_boundary(d2.X, lambda x: predict(net, x))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VhRdiSB3yPmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training set, loss function, and optimization algorithm\n",
        "...\n",
        "\n",
        "# Trainer loop\n",
        "..."
      ],
      "metadata": {
        "id": "iB789iKayPGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What are the parameter values after training?\n",
        "for name, param in net.named_parameters():\n",
        "    print(name, '\\t', param.data)\n",
        "\n",
        "# Where is the decision boundary after training?\n",
        "plt.figure(figsize=(5,5))\n",
        "plot_points(d2.X, d2.y)\n",
        "plt.axis('equal')\n",
        "plt.xlim(-8, 8)\n",
        "plt.ylim(-8, 8)\n",
        "plot_boundary(d2.X, lambda x: predict(net, x))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9AThiEzKymW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise Q3: three-way classification"
      ],
      "metadata": {
        "id": "VB1AjlWex0ZS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHwOIeaazQ_v"
      },
      "outputs": [],
      "source": [
        "# Data...\n",
        "d3 = D3(100)\n",
        "plt.figure(figsize=(5,5))\n",
        "plot_points(d3.X, d3.y)\n",
        "plt.axis('equal')\n",
        "plt.xlim(-8, 8)\n",
        "plt.ylim(-8, 8)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model...\n",
        "class Net3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # TODO: put neural net structure here\n",
        "        ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: define the forward pass here\n",
        "        ...\n",
        "\n",
        "torch.random.manual_seed(1)\n",
        "net = Net3()\n",
        "\n",
        "print('Number of learnable float-valued parameters', count_parameters(net))\n",
        "print('Neural net architecture:')\n",
        "print(net)"
      ],
      "metadata": {
        "id": "UpWDJIXt4Bxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Before training...\n",
        "\n",
        "# What are the parameter values before training?\n",
        "for name, param in net.named_parameters():\n",
        "    print(name, '\\t', param.data)\n",
        "\n",
        "# Where is the decision boundary before training?\n",
        "plt.figure(figsize=(5,5))\n",
        "plot_points(d3.X, d3.y)\n",
        "plt.axis('equal')\n",
        "plt.xlim(-8, 8)\n",
        "plt.ylim(-8, 8)\n",
        "plot_boundary(d3.X, lambda x: predict(net, x), num_classes=3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S184gBSKrAQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train...\n",
        "\n",
        "# Training set, loss function, and optimization algorithm\n",
        "...\n",
        "\n",
        "# Trainer loop\n",
        "..."
      ],
      "metadata": {
        "id": "eSMXgpdG1E2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After training...\n",
        "\n",
        "# What are the parameter values after training?\n",
        "for name, param in net.named_parameters():\n",
        "    print(name, '\\t', param.data)\n",
        "\n",
        "# Where is the decision boundary after training?\n",
        "plt.figure(figsize=(5,5))\n",
        "plot_points(d3.X, d3.y)\n",
        "plt.axis('equal')\n",
        "plt.xlim(-8, 8)\n",
        "plt.ylim(-8, 8)\n",
        "plot_boundary(d1.X, lambda x: predict(net, x), num_classes=3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HkL-9MBIvw8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise Q4: Architecture Choices & Effects"
      ],
      "metadata": {
        "id": "P2C5N8kcA1Jk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EVsSE4fQA2id"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}